{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from models import SCrossEntropyLoss, SMLP3, SMLP4, SLeNet, CIFAR, FakeSCrossEntropyLoss\n",
    "import modules\n",
    "from qmodels import QSLeNet, QCIFAR\n",
    "import resnet\n",
    "import qresnet\n",
    "import qvgg\n",
    "import qdensnet\n",
    "from modules import SModule\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "from cw_attack import Attack, WCW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def CEval():\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    # model.clear_noise()\n",
    "    with torch.no_grad():\n",
    "        # for images, labels in tqdm(testloader):\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            if len(outputs) == 2:\n",
    "                outputs = outputs[0]\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).cpu().numpy()\n",
    "\n",
    "def NEval(dev_var, write_var):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "    with torch.no_grad():\n",
    "        model.set_noise(dev_var, write_var)\n",
    "        for images, labels in tqdm(testloader):\n",
    "        # for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            if len(outputs) == 2:\n",
    "                outputs = outputs[0]\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).cpu().numpy()\n",
    "\n",
    "def NEachEval(dev_var, write_var):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader):\n",
    "        # for images, labels in testloader:\n",
    "            model.clear_noise()\n",
    "            model.set_noise(dev_var, write_var)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            if len(outputs) == 2:\n",
    "                outputs = outputs[0]\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).cpu().numpy()\n",
    "\n",
    "def NTrain(epochs, header, dev_var=0.0, write_var=0.0, verbose=False):\n",
    "    best_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        for images, labels in tqdm(trainloader):\n",
    "        # for images, labels in trainloader:\n",
    "            model.clear_noise()\n",
    "            model.set_noise(dev_var, write_var)\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            loss = criteriaF(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # test_acc = NEachEval(dev_var, write_var)\n",
    "        test_acc = CEval()\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), f\"tmp_best_{header}.pt\")\n",
    "        if verbose:\n",
    "            print(f\"epoch: {i:-3d}, test acc: {test_acc:.4f}, loss: {running_loss / len(trainloader):.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "def str2bool(a):\n",
    "    if a == \"True\":\n",
    "        return True\n",
    "    elif a == \"False\":\n",
    "        return False\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha=1000000.0, calc_S=True, dev_var=0.3, device='cuda:0', div=1, header=1, layerwise=False, mask_p=0.01, method='SM', model='MLP4', model_path='./pretrained', noise_epoch=100, pretrained=True, save_file=True, train_epoch=20, train_var=0.0, use_mask=True, verbose=False, write_var=0.03)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train_epoch', action='store', type=int, default=20,\n",
    "        help='# of epochs of training')\n",
    "parser.add_argument('--noise_epoch', action='store', type=int, default=100,\n",
    "        help='# of epochs of noise validations')\n",
    "parser.add_argument('--train_var', action='store', type=float, default=0.0,\n",
    "        help='device variation [std] when training')\n",
    "parser.add_argument('--dev_var', action='store', type=float, default=0.3,\n",
    "        help='device variation [std] before write and verify')\n",
    "parser.add_argument('--write_var', action='store', type=float, default=0.03,\n",
    "        help='device variation [std] after write and verify')\n",
    "parser.add_argument('--mask_p', action='store', type=float, default=0.01,\n",
    "        help='portion of the mask')\n",
    "parser.add_argument('--device', action='store', default=\"cuda:0\",\n",
    "        help='device used')\n",
    "parser.add_argument('--verbose', action='store', type=str2bool, default=False,\n",
    "        help='see training process')\n",
    "parser.add_argument('--model', action='store', default=\"MLP4\", choices=[\"MLP3\", \"MLP4\", \"LeNet\", \"CIFAR\", \"Res18\", \"TIN\", \"QLeNet\", \"QCIFAR\", \"QRes18\", \"QDENSE\", \"QTIN\", \"QVGG\"],\n",
    "        help='model to use')\n",
    "parser.add_argument('--method', action='store', default=\"SM\", choices=[\"second\", \"magnitude\", \"saliency\", \"random\", \"SM\"],\n",
    "        help='method used to calculate saliency')\n",
    "parser.add_argument('--alpha', action='store', type=float, default=1e6,\n",
    "        help='weight used in saliency - substract')\n",
    "parser.add_argument('--header', action='store',type=int, default=1,\n",
    "        help='use which saved state dict')\n",
    "parser.add_argument('--pretrained', action='store',type=str2bool, default=True,\n",
    "        help='if to use pretrained model')\n",
    "parser.add_argument('--use_mask', action='store',type=str2bool, default=True,\n",
    "        help='if to do the masking experiment')\n",
    "parser.add_argument('--model_path', action='store', default=\"./pretrained\",\n",
    "        help='where you put the pretrained model')\n",
    "parser.add_argument('--save_file', action='store',type=str2bool, default=True,\n",
    "        help='if to save the files')\n",
    "parser.add_argument('--calc_S', action='store',type=str2bool, default=True,\n",
    "        help='if calculated S grad if not necessary')\n",
    "parser.add_argument('--div', action='store', type=int, default=1,\n",
    "        help='division points for second')\n",
    "parser.add_argument('--layerwise', action='store',type=str2bool, default=False,\n",
    "        help='if do it layer by layer')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "print(args)\n",
    "header = time.time()\n",
    "header_timer = header\n",
    "parent_path = \"./\"\n",
    "\n",
    "device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BS = 128\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "                                            \n",
    "# normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "# transform = transforms.Compose(\n",
    "# [transforms.ToTensor(),\n",
    "# #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "#         normalize])\n",
    "# train_transform = transforms.Compose([\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomCrop(32, 4),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#         ])\n",
    "# trainset = torchvision.datasets.CIFAR10(root='~/Private/data', train=True, download=False, transform=train_transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS, shuffle=True, num_workers=4)\n",
    "# secondloader = torch.utils.data.DataLoader(trainset, batch_size=BS//args.div, shuffle=False, num_workers=4)\n",
    "# testset = torchvision.datasets.CIFAR10(root='~/Private/data', train=False, download=False, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=BS, shuffle=False, num_workers=4)\n",
    "\n",
    "# model = CIFAR()\n",
    "model = SLeNet()\n",
    "# model = QSLeNet()\n",
    "\n",
    "model.to(device)\n",
    "model.push_S_device()\n",
    "model.clear_noise()\n",
    "model.clear_mask()\n",
    "criteria = SCrossEntropyLoss()\n",
    "criteriaF = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [60])\n",
    "args.train_epoch = 20\n",
    "args.dev_var = 0.3\n",
    "# args.train_var = 0.3\n",
    "args.train_var = 0.03\n",
    "args.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_first_only()\n",
    "NTrain(args.train_epoch, header, args.train_var, 0.0, args.verbose)\n",
    "if args.train_var > 0:\n",
    "    state_dict = torch.load(f\"tmp_best_{header}.pt\")\n",
    "    model.load_state_dict(state_dict)\n",
    "model.from_first_back_second()\n",
    "torch.save(model.state_dict(), f\"saved_B_{header}_{args.train_var}.pt\")\n",
    "model.clear_noise()\n",
    "print(f\"No mask no noise: {CEval():.4f}\")\n",
    "state_dict = torch.load(f\"saved_B_{header}_{args.train_var}.pt\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.clear_mask()\n",
    "performance = NEachEval(args.dev_var, 0.0)\n",
    "print(f\"No mask noise acc: {performance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train_var = 0.1\n",
    "header = 3\n",
    "model.from_first_back_second()\n",
    "state_dict = torch.load(f\"pretrained/saved_B_{header}_{args.train_var}.pt\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.clear_mask()\n",
    "model.clear_noise()\n",
    "# print(f\"No mask no noise: {CEval():.4f}\")\n",
    "# print(f\"No mask w/ noise: {NEachEval(args.dev_var, args.write_var):.4f}\")\n",
    "model.to_first_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 0.370\n",
      "L2  diff: 0.008\n",
      "Avg  acc: 0.0007\n"
     ]
    }
   ],
   "source": [
    "def my_target(x,y):\n",
    "    return (y+1)%10\n",
    "max_list = []\n",
    "avg_list = []\n",
    "acc_list = []\n",
    "for _ in range(1):\n",
    "    avg_performance = []\n",
    "    model.clear_noise()\n",
    "    attacker = WCW(model, c=1e-4, kappa=0, steps=10, lr=0.01, method=\"l2\")\n",
    "    # attacker.set_mode_targeted_random(n_classses=10)\n",
    "    # attacker.set_mode_targeted_by_function(my_target)\n",
    "    attacker(trainloader)\n",
    "    w = attacker.get_noise()\n",
    "    max_list.append(attacker.noise_max().item())\n",
    "    avg_list.append(np.sqrt(attacker.noise_l2().item()))\n",
    "    accuracy = CEval().item()\n",
    "    acc_list.append(accuracy)\n",
    "print(f\"Max diff: {np.mean(max_list):.3f}\")\n",
    "print(f\"L2  diff: {np.mean(avg_list):.3f}\")\n",
    "print(f\"Avg  acc: {np.mean(acc_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1163, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.noise_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = None\n",
    "for m in model.modules():\n",
    "    if isinstance(m, modules.NModule) or isinstance(m, modules.SModule):\n",
    "        if w is None:\n",
    "            w = m.noise.view(-1)\n",
    "        else:\n",
    "            w= torch.cat([w, m.noise.view(-1)])\n",
    "len(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigma = 0.0\n",
    "acc:   98.78+ 98.64+ 98.79  \n",
    "noise: 72.24+ 76.76+ 71.92\n",
    "max:   0.061+ 0.063+ 0.062\n",
    "l2:    0.012+ 0.013+ 0.012\n",
    "adv:   09.55+ 10.22+ 11.43\n",
    "\n",
    "### sigma = 0.01\n",
    "\n",
    "acc:   99.04+ 98.88+ 99.04\n",
    "noise: 81.79+ 86.93+ 87.27\n",
    "max:   0.067+ 0.065+ 0.066\n",
    "l2:    0.012+ 0.010+ 0.011\n",
    "adv:   09.12+ 11.23+ 07.36\n",
    "\n",
    "### sigma = 0.05\n",
    "\n",
    "acc:   98.80+ 98.80+ 99.05\n",
    "noise: 95.71+ 94.72+ 95.43\n",
    "max:   0.062+ 0.058+ 0.065\n",
    "l2:    0.012+ 0.011+ 0.012\n",
    "adv:   16.02+ 12.20+ 11.43\n",
    "\n",
    "### sigma = 0.1\n",
    "acc:   98.95+ 99.06+ 98.93\n",
    "noise: 97.36+ 97.91+ 97.18\n",
    "max:   0.078+ 0.083+ 0.063\n",
    "l2:    0.013+ 0.013+ 0.011\n",
    "adv:   14.42+ 16.89+ 11.49\n",
    "\n",
    "### sigma = 0.2\n",
    "acc:   99.13+ 98.97+ 99.00\n",
    "noise: 98.47+ 98.36+ 98.51\n",
    "max:   0.068+ 0.065+ 0.053\n",
    "l2:    0.013+ 0.012+ 0.012\n",
    "adv:   16.28+ 14.42+ 12.93\n",
    "\n",
    "### sigma = 0.3\n",
    "acc:   99.01+ 99.04+ 99.03\n",
    "noise: 98.72+ 98.58+ 98.80\n",
    "max:   0.078+ 0.061+ 0.061\n",
    "l2:    0.012+ 0.013+ 0.012\n",
    "adv:   15.08+ 21.96+ 20.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in trainloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    loss = criteriaF(outputs,labels)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clear_noise()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, modules.NModule) or isinstance(m, modules.SModule):\n",
    "        m.noise = m.op.weight.grad.data.sign() * 0.1 * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.1585, dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04f3ce0738d928d74413a2b10d0d4c487f39bbf2ffd0e3f43a6ab028b956cd75"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
