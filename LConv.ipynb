{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd004f3ce0738d928d74413a2b10d0d4c487f39bbf2ffd0e3f43a6ab028b956cd75",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(c, size, i):\n",
    "    res = torch.zeros(size, device=c.device)\n",
    "    res[:i] = c[i:]\n",
    "    return res\n",
    "\n",
    "def toeplitz(c, r):\n",
    "    if len(c.size()) == 3:\n",
    "        IC, OC, l_r = r.size()\n",
    "        l_c = c.size()[-1]\n",
    "        res = torch.zeros(IC,OC, l_c, l_r, device=c.device)\n",
    "        # p = torch.zeros(len(c))\n",
    "        # c = torch.cat([p,c.flip(0)])\n",
    "        c = c.flip(2)\n",
    "        c = torch.cat([c,c],dim=2)\n",
    "        for i in range(1, l_c + 1):\n",
    "            if i <= l_r:\n",
    "                res[:,:,i-1,:i] = c[:,:,-i:]\n",
    "            else:\n",
    "                res[:,:,i-1,:] = c[:,:,-i:-i+l_r]\n",
    "        return res\n",
    "    if len(c.size()) == 1:\n",
    "        l_r = r.size()[0]\n",
    "        l_c = c.size()[0]\n",
    "        res = torch.zeros(l_c, l_r, device=c.device)\n",
    "        # p = torch.zeros(len(c))\n",
    "        # c = torch.cat([p,c.flip(0)])\n",
    "        c = c.flip(0)\n",
    "        c = torch.cat([c,c])\n",
    "        for i in range(1, l_c + 1):\n",
    "            if i <= l_r:\n",
    "                res[i-1,:i] = c[-i:]\n",
    "            else:\n",
    "                res[i-1,:] = c[-i:-i+l_r]\n",
    "        return res\n",
    "\n",
    "def vector_to_matrix(input, output_shape):\n",
    "    B, C, output_h, output_w = output_shape\n",
    "    output = torch.zeros(output_shape, dtype=input.dtype, device=input.device)\n",
    "    for i in range(output_h):\n",
    "        st = i*output_w\n",
    "        nd = st + output_w\n",
    "        output[:,:, i, :] = input[:,:,st:nd]\n",
    "    # flip the output matrix up-down to get correct result\n",
    "    output=torch.flip(output,dims=[-2])\n",
    "    return output\n",
    "\n",
    "def matrix_to_vector(input):\n",
    "    B, C, input_h, input_w = input.shape\n",
    "    output_vector = torch.zeros(B, C, input_h*input_w, dtype=input.dtype, device=input.device)\n",
    "    # flip the input matrix up-down because last row should go first\n",
    "    input = torch.flip(input,dims=[-2]) \n",
    "    for i in range(input.size()[2]):\n",
    "        st = i*input_w\n",
    "        nd = st + input_w\n",
    "        output_vector[:,:,st:nd] = input[:,:,i]\n",
    "        \n",
    "    return output_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lol(I,F):\n",
    "    st = time.time()\n",
    "    I_B, I_C, I_row_num, I_col_num = I.size() \n",
    "\n",
    "    # number of columns and rows of the filter\n",
    "    F_CO, F_CI, F_row_num, F_col_num = F.size()\n",
    "\n",
    "    #  calculate the output dimensions\n",
    "    output_row_num = I_row_num + F_row_num - 1\n",
    "    output_col_num = I_col_num + F_col_num - 1\n",
    "\n",
    "    F_zero_padded = torch.zeros(F_CO, F_CI, output_row_num, output_col_num, device=I.device)\n",
    "    F_zero_padded[:, :, -F_row_num:, :F_col_num] = F\n",
    "\n",
    "    toeplitz_list = []\n",
    "    for i in range(F_zero_padded.shape[2]-1, -1, -1): # iterate from last row to the first row\n",
    "        c = F_zero_padded[:, :, i, :] # i th row of the F \n",
    "        r = torch.zeros(F_CO, F_CI, I_col_num, device=I.device)\n",
    "        r[:,:,0] = c[:,:,0]\n",
    "        toeplitz_m = toeplitz(c, r)\n",
    "        toeplitz_list.append(toeplitz_m)\n",
    "\n",
    "    c = torch.Tensor(range(1, F_zero_padded.shape[2]+1)).to(I.device)\n",
    "    r = torch.zeros(I_row_num, device=I.device)\n",
    "    r[0] = c[0]\n",
    "    doubly_indices = toeplitz(c, r).to(torch.int)\n",
    "    # print(doubly_indices)\n",
    "\n",
    "    toeplitz_shape = toeplitz_list[0].shape # shape of one toeplitz matrix\n",
    "    h = toeplitz_shape[2]*doubly_indices.shape[0]\n",
    "    w = toeplitz_shape[3]*doubly_indices.shape[1]\n",
    "    doubly_blocked_shape = [F_CO, F_CI, h, w]\n",
    "    doubly_blocked = torch.zeros(doubly_blocked_shape, device=I.device)\n",
    "\n",
    "    # tile toeplitz matrices for each row in the doubly blocked matrix\n",
    "    IC, OC, b_h, b_w = toeplitz_shape # hight and withs of each block\n",
    "    for i in range(doubly_indices.shape[0]):\n",
    "        for j in range(doubly_indices.shape[1]):\n",
    "            start_i = i * b_h\n",
    "            start_j = j * b_w\n",
    "            end_i = start_i + b_h\n",
    "            end_j = start_j + b_w\n",
    "            doubly_blocked[:,:,start_i: end_i, start_j:end_j] = toeplitz_list[doubly_indices[i,j]-1]\n",
    "    \n",
    "    print(\"sad\")\n",
    "    # print(doubly_blocked.shape)\n",
    "    vectorized_I = matrix_to_vector(I)\n",
    "    # print(vectorized_I.shape)\n",
    "    # print(vectorized_I)\n",
    "    output_vect = torch.zeros(I_B, F_CO, output_row_num * output_col_num, device=I.device)\n",
    "    # print(doubly_blocked.shape)\n",
    "    for i in tqdm(range(I_B)):\n",
    "        # for j in range(F_CO):\n",
    "            for k in range(I_C):\n",
    "                output_vect[i,:,:] += torch.matmul(doubly_blocked[:,k].view(F_CO,h,w), vectorized_I[i,k,:].view(I_row_num * I_col_num))\n",
    "    out_shape = [I_B, F_CO, output_row_num, output_col_num]\n",
    "    my_output = vector_to_matrix(output_vect, out_shape)\n",
    "    print(time.time() - st)\n",
    "    return my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sad\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=32.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f23abf73164c4a4f8a206bf36a0fe748"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n3.24786376953125\n3.2758641242980957\ntensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "I = torch.randn(32,16,16,16).to(device)\n",
    "F = torch.randn(64,16,3,3).to(device)\n",
    "# I = torch.Tensor([[[[1, 2, 3], [4, 5, 6], [7,8,9]], [[1, 2, 3], [4, 5, 6], [7,8,9]]]])\n",
    "# I = torch.ones(1,2,3,3)\n",
    "model = torch.nn.Conv2d(16,64,3,padding=2).to(device)\n",
    "# F = torch.Tensor([[[[10, 20, 30], [40, 50, 60], [70, 80, 90]],[[10, 20, 30], [40, 50, 60], [70, 80, 90]]]])\n",
    "# F = torch.ones(1,2,3,3)\n",
    "model.weight.data = F.flip(dims=[-1,-2])\n",
    "model.bias.data = torch.zeros_like(model.bias)\n",
    "# print(I.shape)\n",
    "m_res = model(I)\n",
    "st = time.time()\n",
    "a = lol(I,F)#.numpy()\n",
    "# print(torch.prod(torch.Tensor(a.shape)))\n",
    "print(time.time() - st)\n",
    "print(((a - m_res).abs() < 1e-4).sum() / torch.prod(torch.Tensor(list(a.shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}