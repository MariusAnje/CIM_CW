{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "04f3ce0738d928d74413a2b10d0d4c487f39bbf2ffd0e3f43a6ab028b956cd75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from models import SCrossEntropyLoss, SMLP3, SMLP4, SLeNet, FakeSCrossEntropyLoss\n",
    "from modules import SModule\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def eval():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "    model.clear_mask()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def Seval():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        model.clear_noise()\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs[0].argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def Seval_noise(var):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.set_noise(var)\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs[0].argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def STrain(epochs, header, verbose=False):\n",
    "    best_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.\n",
    "        running_l = 0.\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # images = images.view(-1, 784)\n",
    "            outputs, outputsS = model(images)\n",
    "            loss = criteria(outputs, outputsS,labels)\n",
    "            loss.backward()\n",
    "            l = loss + model.fetch_S_grad()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_l += l.item()\n",
    "        test_acc = Seval()\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), f\"tmp_best_{header}.pt\")\n",
    "        if verbose:\n",
    "            print(f\"epoch: {i:-3d}, test acc: {test_acc:.4f}, loss: {running_loss / len(trainloader):.4f}, s: {(running_l - running_loss) / len(trainloader):-5.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "def GetSecond():\n",
    "    model.clear_noise()\n",
    "    optimizer.zero_grad()\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # images = images.view(-1, 784)\n",
    "        outputs, outputsS = model(images)\n",
    "        loss = criteria(outputs, outputsS,labels)\n",
    "        loss.backward()\n",
    "\n",
    "def str2bool(a):\n",
    "    if a == \"True\":\n",
    "        return True\n",
    "    elif a == \"False\":\n",
    "        return False\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No mask noise average acc: 0.9404, std: 0.0330\n",
      "S grad before masking: 9.017338E+06\n"
     ]
    }
   ],
   "source": [
    "header = time.time()\n",
    "header_timer = header\n",
    "parent_path = \"./\"\n",
    "train_epoch = 20\n",
    "verbose = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BS = 128\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "model = SLeNet()\n",
    "\n",
    "model.to(device)\n",
    "model.push_S_device()\n",
    "model.clear_noise()\n",
    "model.clear_mask()\n",
    "criteria = SCrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [20])\n",
    "pretrained = True\n",
    "if not pretrained:\n",
    "    STrain(train_epoch, header, verbose)\n",
    "    \n",
    "    state_dict = torch.load(f\"tmp_best_{header}.pt\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    torch.save(model.state_dict(), f\"saved_B_{header}.pt\")\n",
    "\n",
    "    no_mask_acc_list = []\n",
    "    state_dict = torch.load(f\"saved_B_{header}.pt\")\n",
    "    print(f\"No mask no noise: {Seval():.4f}\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.clear_mask()\n",
    "    loader = range(10)\n",
    "    for _ in loader:\n",
    "        acc = Seval_noise(0.2)\n",
    "        no_mask_acc_list.append(acc)\n",
    "    print(f\"No mask noise average acc: {np.mean(no_mask_acc_list):.4f}, std: {np.std(no_mask_acc_list):.4f}\")\n",
    "    torch.save(no_mask_acc_list, f\"no_mask_list_{header}.pt\")\n",
    "\n",
    "else:\n",
    "    parent_path = \"./pretrained\"\n",
    "    header = 6\n",
    "    no_mask_acc_list = torch.load(os.path.join(parent_path, f\"no_mask_list_{header}.pt\"))\n",
    "    print(f\"No mask noise average acc: {np.mean(no_mask_acc_list):.4f}, std: {np.std(no_mask_acc_list):.4f}\")\n",
    "    model.back_real(device)\n",
    "    model.push_S_device()\n",
    "\n",
    "state_dict = torch.load(os.path.join(parent_path, f\"saved_B_{header}.pt\"), map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.back_real(device)\n",
    "model.push_S_device()\n",
    "criteria = SCrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [20])\n",
    "model.clear_noise()\n",
    "GetSecond()\n",
    "print(f\"S grad before masking: {model.fetch_S_grad().item():E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "no mask no noise: 0.9920\n"
     ]
    }
   ],
   "source": [
    "p_list = np.arange(0, 1, 0.01)\n",
    "model.clear_mask()\n",
    "print(f\"no mask no noise: {Seval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_th_acc_list = []\n",
    "for i in p_list:\n",
    "    model.clear_mask()\n",
    "    mask_p = i\n",
    "    th = model.calc_S_grad_th(1 - mask_p)\n",
    "    model.set_mask(th, mode=\"th\")\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, SModule):\n",
    "            m.mask = 1 - m.mask\n",
    "    acc = Seval()\n",
    "    s_th_acc_list.append(acc)\n",
    "# print(s_th_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pt_acc_list = []\n",
    "for i in p_list:\n",
    "    model.clear_mask()\n",
    "    mask_p = i\n",
    "    th = model.calc_S_grad_th(1 - mask_p)\n",
    "    model.set_mask(1-i, mode=\"portion\")\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, SModule):\n",
    "            m.mask = 1 - m.mask\n",
    "    acc = Seval()\n",
    "    s_pt_acc_list.append(acc)\n",
    "# print(s_pt_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pt_acc_list = []\n",
    "for i in p_list:\n",
    "    model.clear_mask()\n",
    "    mask_p = i\n",
    "    th = model.calc_S_grad_th(1 - mask_p)\n",
    "    model.set_mask_mag(1-i, mode=\"portion\")\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, SModule):\n",
    "            m.mask = 1 - m.mask\n",
    "    acc = Seval()\n",
    "    m_pt_acc_list.append(acc)\n",
    "# print(m_pt_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(p_list, s_th_acc_list)\n",
    "plt.plot(p_list, s_pt_acc_list)\n",
    "plt.plot(p_list, m_pt_acc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(105918.)\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, SModule):\n",
    "        size = torch.prod(torch.Tensor(list(m.op.weight.shape)))\n",
    "        t += size\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}